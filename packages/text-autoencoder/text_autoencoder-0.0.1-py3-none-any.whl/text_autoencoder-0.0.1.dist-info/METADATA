Metadata-Version: 2.1
Name: text-autoencoder
Version: 0.0.1
Summary: Yoctol Natural Language Text Autoencoder
Home-page: UNKNOWN
Author: Solumilken
License: MIT
Platform: UNKNOWN
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.6
Requires-Python: >=3.6
Requires-Dist: numpy (==1.14.2)
Requires-Dist: tensorflow (==1.7.0)
Requires-Dist: bistiming (==0.1.1)
Requires-Dist: mkdir-p (==0.1.1)
Requires-Dist: pyyaml (==3.13)
Requires-Dist: u-msgpack-python (==2.5.0)
Requires-Dist: tqdm (==4.23.4)
Requires-Dist: serving-utils (==0.4.3)

# text-autoencoder

[![travis][travis-image]][travis-url]
[![pypi][pypi-image]][pypi-url]

[travis-image]: https://img.shields.io/travis/Yoctol/text-autoencoder.svg?style=flat
[travis-url]: https://travis-ci.org/Yoctol/text-autoencoder
[pypi-image]: https://img.shields.io/pypi/v/text-autoencoder.svg?style=flat
[pypi-url]: https://pypi.python.org/pypi/text-autoencoder

Various autoencoder for text data.

## Usage

### Grab one autoencoder first
```python
from text_autoencoder.variational_autoencoders import VAEXXX
model = VAEXXX(n_steps=..., latent_size=..., state_size=..., ...)
```

### How to train
- Warning: please preprocess your data to be a numpy array with shape (data_size, maxlen, embedding_size)
```python
model.fit(x=..., mask=..., epochs=10)
```

### How to save model
```python
model.save(output_path)
```

### How to get latent vector `z`
```python
model.get_latent_vector(x=..., mask=..., batch_size=1)
```

### How to get output of encoder
```python
model.encode(x=..., mask=..., batch_size=1)
```

### How to load a trained model
```python
model.load(path)
```

### How to monitor the training process
- get the output_dir you input when calling `model.fit`
- monitor training loss
```shell
> tensorboard --logdir="<output_dir>/summary/subtrain/"
```

- monitor validation loss
```shell
> tensorboard --logdir="<output_dir>/summary/valid/"
```


