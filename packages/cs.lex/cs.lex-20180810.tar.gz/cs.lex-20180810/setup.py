#!/usr/bin/env python
from setuptools import setup
setup(
  name = 'cs.lex',
  description = 'lexical analysis, tokenisers',
  author = 'Cameron Simpson',
  author_email = 'cs@cskk.id.au',
  version = '20180810',
  url = 'https://bitbucket.org/cameron_simpson/css/commits/all',
  classifiers = ['Programming Language :: Python', 'Programming Language :: Python :: 2', 'Programming Language :: Python :: 3', 'Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Topic :: Software Development :: Libraries :: Python Modules', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)'],
  install_requires = ['cs.py3'],
  keywords = ['python2', 'python3'],
  long_description = 'Lexical analysis functions, tokenisers.\n\nAn arbitrary assortment of lexical and tokenisation functions useful\nfor writing recursive descent parsers, of which I have several.\n\nGenerally the get_* functions accept a source string and an offset\n(often optional, default 0) and return a token and the new offset,\nraising ValueError on failed tokenisation.\n\n## Function `as_lines(chunks, partials=None)`\n\nGenerator yielding complete lines from arbitrary pieces text\nfrom the iterable `chunks`.\n\nAfter completion, any remaining newline-free chunks remain\nin the partials list; this will be unavailable to the caller\nunless the list is presupplied.\n\n## Function `get_chars(s, offset, gochars)`\n\nScan the string `s` for characters in `gochars` starting at `offset`.\nReturn (match, new_offset).\n\n## Function `get_decimal(s, offset=0)`\n\nScan the string `s` for decimal characters starting at `offset`.\nReturn dec_string, new_offset.\n\n## Function `get_delimited(s, offset, delim)`\n\nCollect text from the string `s` from position `offset` up to the first occurence of delimiter `delim`; return the text excluding the delimiter and the offset after the delimiter.\n\n## Function `get_dotted_identifier(s, offset=0, **kw)`\n\nScan the string `s` for a dotted identifier (by default an\nASCII letter or underscore followed by letters, digits or\nunderscores) with optional trailing dot and another dotted\nidentifier, starting at `offset` (default 0).\nReturn (match, new_offset).\n\nThe empty string and an unchanged offset will be returned if\nthere is no leading letter/underscore.\n\n## Function `get_envvar(s, offset=0, environ=None, default=None, specials=None)`\n\nParse a simple environment variable reference to $varname or\n$x where "x" is a special character.\n\nParamaters:\n* `s`: the string with the variable reference\n* `offset`: the starting point for the reference\n* `default`: default value for missing environment variables;\n   if None (the default) a ValueError is raised\n* `environ`: the environment mapping, default os.environ\n* `specials`: the mapping of special single character variables\n\n## Function `get_hexadecimal(s, offset=0)`\n\nScan the string `s` for hexadecimal characters starting at `offset`.\nReturn hex_string, new_offset.\n\n## Function `get_identifier(s, offset=0, alpha=\'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\', number=\'0123456789\', extras=\'_\')`\n\nScan the string `s` for an identifier (by default an ASCII\nletter or underscore followed by letters, digits or underscores)\nstarting at `offset` (default 0).\nReturn (match, new_offset).\n\nThe empty string and an unchanged offset will be returned if\nthere is no leading letter/underscore.\n\n## Function `get_nonwhite(s, offset=0)`\n\nScan the string `s` for characters not in string.whitespace\nstarting at `offset` (default 0).\nReturn (match, new_offset).\n\n## Function `get_other_chars(s, offset=0, stopchars=None)`\n\nScan the string `s` for characters not in `stopchars` starting\nat `offset` (default 0).\nReturn (match, new_offset).\n\n## Function `get_qstr(s, offset=0, q=\'"\', environ=None, default=None, env_specials=None)`\n\nGet quoted text with slosh escapes and optional environment substitution.\n`s`: the string containg the quoted text.\n`offset`: the starting point, default 0.\n`q`: the quote character, default \'"\'. If `q` is set to None,\n  do not expect the string to be delimited by quote marks.\n`environ`: if not None, also parse and expand $envvar references.\n`default`: passed to get_envvar\n\n## Function `get_sloshed_text(s, delim, offset=0, slosh=\'\\\\\', mapper=<function slosh_mapper at 0x1040b4268>, specials=None)`\n\nCollect slosh escaped text from the string `s` from position\n`offset` (default 0) and return the decoded unicode string and\nthe offset of the completed parse.\n\nParameters:\n`delim`: end of string delimiter, such as a single or double quote.\n`offset`: starting offset within `s`, default 0.\n`slosh`: escape character, default a slosh (\'\\\').\n`mapper`: a mapping function which accepts a single character\n  and returns a replacement string or None; this is used the\n  replace things such as \'\\t\' or \'\\n\'. The default is the\n  slosh_mapper function, whose default mapping is SLOSH_CHARMAP.\n`specials`: a mapping of other special character sequences and parse\n  functions for gathering them up. When one of the special\n  character sequences is found in the string, the parse\n  function is called to parse at that point.\n  The parse functions accept\n  `s` and the offset of the special character. They return\n  the decoded string and the offset past the parse.\n\nThe escape character `slosh` introduces an encoding of some\nreplacement text whose value depends on the following character.\nIf the following character is:\n  - the escape character `slosh`, insert the escape character.\n  - the string delimiter `delim`, insert the delimiter.\n  - the character \'x\', insert the character with code from\n    the following 2 hexadecimal digits.\n  - the character \'u\', insert the character with code from\n    the following 4 hexadecimal digits.\n  - the character \'U\', insert the character with code from\n    the following 8 hexadecimal digits.\n  - a character from the keys of mapper\n\n## Function `get_tokens(s, offset, getters)`\n\nParse the string `s` from position `offset` using the supplied tokenise functions `getters`; return the list of tokens matched and the final offset.\n`s`: the string to parse.\n`offset`: the starting position for the parse.\n`getters`: an iterable of tokeniser specifications.\nEach tokeniser specification is either:\n- a callable expecting (s, offset) and returning (token, new_offset)\n- a literal string, to be matched exactly\n- a tuple or list with values (func, args, kwargs);\n  call func(s, offset, *args, **kwargs)\n- an object with a .match method such as a regex;\n  call getter.match(s, offset) and return a match object with\n  a .end() method returning the offset of the end of the match\n\n## Function `get_uc_identifier(s, offset=0, number=\'0123456789\', extras=\'_\')`\n\nScan the string `s` for an identifier as for get_identifier(), but require the letters to be uppercase.\n\n## Function `get_white(s, offset=0)`\n\nScan the string `s` for characters in string.whitespace\nstarting at `offset` (default 0).\nReturn (match, new_offset).\n\n## Function `htmlify(s, nbsp=False)`\n\nConvert a string for safe transcription in HTML.\n\nParameters:\n* `s`: the string\n* `nbsp`: replaces spaces with "&nbsp;" to prevent word folding, default `False`.\n\n## Function `is_dotted_identifier(s, offset=0, **kw)`\n\nTest if the string `s` is an identifier from position `offset` onward.\n\n## Function `is_identifier(s, offset=0, **kw)`\n\nTest if the string `s` is an identifier from position `offset` onward.\n\n## Function `isUC_(s)`\n\nCheck that a string matches ^[A-Z][A-Z_0-9]*$.\n\n## Function `jsquote(s)`\n\nQuote a string for use in JavaScript.\n\n## Function `lastlinelen(s)`\n\nThe length of text after the last newline in a string.\nInitially used by cs.hier to compute effective text width.\n\n## Function `match_tokens(s, offset, getters)`\n\nWrapper for get_tokens which catches ValueError exceptions and returns (None, offset).\n\n## Function `parseUC_sAttr(attr)`\n\nTake an attribute name and return (key, isplural).\nFOO returns (FOO, False).\nFOOs or FOOes returns (FOO, True).\nOtherwise return (None, False).\n\n## Function `phpquote(s)`\n\nQuote a string for use in PHP code.\n\n## Function `skipwhite(s, offset=0)`\n\nConvenience routine for skipping past whitespace;\nreturns offset of next nonwhitespace character.\n\n## Function `slosh_mapper(c, charmap={\'a\': \'\\x07\', \'b\': \'\\x08\', \'f\': \'\\x0c\', \'n\': \'\\n\', \'r\': \'\\r\', \'t\': \'\\t\', \'v\': \'\\x0b\'})`\n\nReturn a string to replace backslash-`c`, or None.\n\n## Function `stripped_dedent(s)`\n\nSlightly smarter dedent.\n\nStrip the supplied string `s`. Pull off the leading line.\nDedent the rest. Put back the leading line.\n\n## Function `texthexify(bs, shiftin=\'[\', shiftout=\']\', whitelist=None)`\n\nTranscribe the bytes `bs` to text.\n\n`whitelist`: a bytes or string object indicating byte values\n  which may be represented directly in text; string objects are\n  converted to hexify() and texthexify() output strings may be\n  freely concatenated and decoded with untexthexify().\n\n## Function `unctrl(s, tabsize=8)`\n\nReturn the string `s` with TABs expanded and control characters\nreplaced with printably representations.\n\n## Function `untexthexify(s, shiftin=\'[\', shiftout=\']\')`\n\nDecode a textual representation of binary data into binary data.\n\nOutside of the `shiftin`/`shiftout` markers the binary data\nare represented as hexadecimal. Within the markers the bytes\nhave the values of the ordinals of the characters.',
  long_description_content_type = 'text/markdown',
  package_dir = {'': 'lib/python'},
  py_modules = ['cs.lex'],
)
