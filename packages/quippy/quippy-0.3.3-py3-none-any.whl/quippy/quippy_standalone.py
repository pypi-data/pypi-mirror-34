# The file was automatically generated by Lark v0.5.5
#
#
#   Lark Stand-alone Generator Tool
# ----------------------------------
# Generates a stand-alone LALR(1) parser with a standard lexer
#
# Git:    https://github.com/erezsh/lark
# Author: Erez Shinan (erezshin@gmail.com)
#
#
#    >>> LICENSE
#
#    This tool and its generated code use a separate license from Lark.
#
#    It is licensed under GPLv2 or above.
#
#    If you wish to purchase a commercial license for this tool and its
#    generated code, contact me via email.
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 2 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    See <http://www.gnu.org/licenses/>.
#
#


import types
import functools
from contextlib import contextmanager

Str = type(u'')

def inline_args(f):
    # print '@@', f.__name__, type(f), isinstance(f, types.FunctionType), isinstance(f, types.TypeType), isinstance(f, types.BuiltinFunctionType)
    if isinstance(f, types.FunctionType):
        @functools.wraps(f)
        def _f_func(self, args):
            return f(self, *args)
        return _f_func
    elif isinstance(f, (type, types.BuiltinFunctionType)):
        @functools.wraps(f)
        def _f_builtin(_self, args):
            return f(*args)
        return _f_builtin
    elif isinstance(f, types.MethodType):
        @functools.wraps(f.__func__)
        def _f(self, args):
            return f.__func__(self, *args)
        return _f
    else:
        @functools.wraps(f.__call__.__func__)
        def _f(self, args):
            return f.__call__.__func__(self, *args)
        return _f


try:
    from contextlib import suppress     # Python 3
except ImportError:
    @contextmanager
    def suppress(*excs):
        '''Catch and dismiss the provided exception

        >>> x = 'hello'
        >>> with suppress(IndexError):
        ...     x = x[10]
        >>> x
        'hello'
        '''
        try:
            yield
        except excs:
            pass


def is_terminal(sym):
    return sym.isupper()

class GrammarError(Exception):
    pass

class ParseError(Exception):
    pass

class UnexpectedToken(ParseError):
    def __init__(self, token, expected, seq, index, considered_rules=None):
        self.token = token
        self.expected = expected
        self.line = getattr(token, 'line', '?')
        self.column = getattr(token, 'column', '?')
        self.considered_rules = considered_rules

        try:
            context = ' '.join(['%r(%s)' % (t.value, t.type) for t in seq[index:index+5]])
        except AttributeError:
            context = seq[index:index+5]
        except TypeError:
            context = "<no context>"
        message = ("Unexpected token %r at line %s, column %s.\n"
                   "Expected: %s\n"
                   "Context: %s" % (token, self.line, self.column, expected, context))

        super(UnexpectedToken, self).__init__(message)



class Tree(object):
    def __init__(self, data, children):
        self.data = data
        self.children = children

    def __repr__(self):
        return 'Tree(%s, %s)' % (self.data, self.children)

    def _pretty_label(self):
        return self.data

    def _pretty(self, level, indent_str):
        if len(self.children) == 1 and not isinstance(self.children[0], Tree):
            return [ indent_str*level, self._pretty_label(), '\t', '%s' % (self.children[0],), '\n']

        l = [ indent_str*level, self._pretty_label(), '\n' ]
        for n in self.children:
            if isinstance(n, Tree):
                l += n._pretty(level+1, indent_str)
            else:
                l += [ indent_str*(level+1), '%s' % (n,), '\n' ]

        return l

    def pretty(self, indent_str='  '):
        return ''.join(self._pretty(0, indent_str))
class Transformer(object):
    def _get_func(self, name):
        return getattr(self, name)

    def transform(self, tree):
        items = []
        for c in tree.children:
            try:
                items.append(self.transform(c) if isinstance(c, Tree) else c)
            except Discard:
                pass
        try:
            f = self._get_func(tree.data)
        except AttributeError:
            return self.__default__(tree.data, items)
        else:
            return f(items)

    def __default__(self, data, children):
        return Tree(data, children)

    def __mul__(self, other):
        return TransformerChain(self, other)


class Discard(Exception):
    pass

class TransformerChain(object):
    def __init__(self, *transformers):
        self.transformers = transformers

    def transform(self, tree):
        for t in self.transformers:
            tree = t.transform(tree)
        return tree

    def __mul__(self, other):
        return TransformerChain(*self.transformers + (other,))



class InlineTransformer(Transformer):
    def _get_func(self, name):  # use super()._get_func
        return inline_args(getattr(self, name)).__get__(self)


class Visitor(object):
    def visit(self, tree):
        for child in tree.children:
            if isinstance(child, Tree):
                self.visit(child)

        f = getattr(self, tree.data, self.__default__)
        f(tree)
        return tree

    def __default__(self, tree):
        pass


class Visitor_NoRecurse(Visitor):
    def visit(self, tree):
        subtrees = list(tree.iter_subtrees())

        for subtree in (subtrees):
            getattr(self, subtree.data, self.__default__)(subtree)
        return tree


class Transformer_NoRecurse(Transformer):
    def transform(self, tree):
        subtrees = list(tree.iter_subtrees())

        def _t(t):
            # Assumes t is already transformed
            try:
                f = self._get_func(t.data)
            except AttributeError:
                return self.__default__(t)
            else:
                return f(t)

        for subtree in subtrees:
            children = []
            for c in subtree.children:
                try:
                    children.append(_t(c) if isinstance(c, Tree) else c)
                except Discard:
                    pass
            subtree.children = children

        return _t(tree)

    def __default__(self, t):
        return t

class Indenter:
    def __init__(self):
        self.paren_level = 0
        self.indent_level = [0]

    def handle_NL(self, token):
        if self.paren_level > 0:
            return

        yield token

        indent_str = token.rsplit('\n', 1)[1] # Tabs and spaces
        indent = indent_str.count(' ') + indent_str.count('\t') * self.tab_len

        if indent > self.indent_level[-1]:
            self.indent_level.append(indent)
            yield Token.new_borrow_pos(self.INDENT_type, indent_str, token)
        else:
            while indent < self.indent_level[-1]:
                self.indent_level.pop()
                yield Token.new_borrow_pos(self.DEDENT_type, indent_str, token)

            assert indent == self.indent_level[-1], '%s != %s' % (indent, self.indent_level[-1])

    def process(self, stream):
        for token in stream:
            if token.type == self.NL_type:
                for t in self.handle_NL(token):
                    yield t
            else:
                yield token

            if token.type in self.OPEN_PAREN_types:
                self.paren_level += 1
            elif token.type in self.CLOSE_PAREN_types:
                self.paren_level -= 1
                assert self.paren_level >= 0

        while len(self.indent_level) > 1:
            self.indent_level.pop()
            yield Token(self.DEDENT_type, '')

        assert self.indent_level == [0], self.indent_level

    # XXX Hack for ContextualLexer. Maybe there's a more elegant solution?
    @property
    def always_accept(self):
        return (self.NL_type,)


class LexError(Exception):
    pass

class UnexpectedInput(LexError):
    def __init__(self, seq, lex_pos, line, column, allowed=None, considered_rules=None):
        context = seq[lex_pos:lex_pos+5]
        message = "No token defined for: '%s' in %r at line %d col %d" % (seq[lex_pos], context, line, column)
        if allowed:
            message += '\n\nExpecting: %s\n' % allowed

        super(UnexpectedInput, self).__init__(message)

        self.line = line
        self.column = column
        self.context = context
        self.allowed = allowed
        self.considered_rules = considered_rules

class Token(Str):
    def __new__(cls, type_, value, pos_in_stream=None, line=None, column=None):
        inst = Str.__new__(cls, value)
        inst.type = type_
        inst.pos_in_stream = pos_in_stream
        inst.value = value
        inst.line = line
        inst.column = column
        return inst

    @classmethod
    def new_borrow_pos(cls, type_, value, borrow_t):
        return cls(type_, value, borrow_t.pos_in_stream, line=borrow_t.line, column=borrow_t.column)

    def __repr__(self):
        return 'Token(%s, %r)' % (self.type, self.value)

    def __deepcopy__(self, memo):
        return Token(self.type, self.value, self.pos_in_stream, self.line, self.column)

    def __eq__(self, other):
        if isinstance(other, Token) and self.type != other.type:
            return False

        return Str.__eq__(self, other)

    __hash__ = Str.__hash__


class LineCounter:
    def __init__(self):
        self.newline_char = '\n'
        self.char_pos = 0
        self.line = 1
        self.column = 0
        self.line_start_pos = 0

    def feed(self, token, test_newline=True):
        """Consume a token and calculate the new line & column.

        As an optional optimization, set test_newline=False is token doesn't contain a newline.
        """
        if test_newline:
            newlines = token.count(self.newline_char)
            if newlines:
                self.line += newlines
                self.line_start_pos = self.char_pos + token.rindex(self.newline_char) + 1

        self.char_pos += len(token)
        self.column = self.char_pos - self.line_start_pos

class _Lex:
    "Built to serve both Lexer and ContextualLexer"
    def __init__(self, lexer):
        self.lexer = lexer

    def lex(self, stream, newline_types, ignore_types):
        newline_types = list(newline_types)
        ignore_types = list(ignore_types)
        line_ctr = LineCounter()

        t = None
        while True:
            lexer = self.lexer
            for mre, type_from_index in lexer.mres:
                m = mre.match(stream, line_ctr.char_pos)
                if m:
                    value = m.group(0)
                    type_ = type_from_index[m.lastindex]
                    if type_ not in ignore_types:
                        t = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
                        if t.type in lexer.callback:
                            t = lexer.callback[t.type](t)
                        yield t
                    else:
                        if type_ in lexer.callback:
                            t = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
                            lexer.callback[type_](t)

                    line_ctr.feed(value, type_ in newline_types)
                    if t:
                        t.end_line = line_ctr.line
                        t.end_column = line_ctr.column
                    break
            else:
                if line_ctr.char_pos < len(stream):
                    raise UnexpectedInput(stream, line_ctr.char_pos, line_ctr.line, line_ctr.column)
                break

class UnlessCallback:
    def __init__(self, mres):
        self.mres = mres

    def __call__(self, t):
        for mre, type_from_index in self.mres:
            m = mre.match(t.value)
            if m:
                value = m.group(0)
                t.type = type_from_index[m.lastindex]
                break
        return t



class ExpandSingleChild:
    def __init__(self, node_builder):
        self.node_builder = node_builder

    def __call__(self, children):
        if len(children) == 1:
            return children[0]
        else:
            return self.node_builder(children)


class CreateToken:
    "Used for fixing the results of scanless parsing"

    def __init__(self, token_name, node_builder):
        self.node_builder = node_builder
        self.token_name = token_name

    def __call__(self, children):
        return self.node_builder( [Token(self.token_name, ''.join(children))] )


class PropagatePositions:
    def __init__(self, node_builder):
        self.node_builder = node_builder

    def __call__(self, children):
        res = self.node_builder(children)

        if children:
            for a in children:
                with suppress(AttributeError):
                    res.line = a.line
                    res.column = a.column
                break

            for a in reversed(children):
                with suppress(AttributeError):
                    res.end_line = a.end_line
                    res.end_column = a.end_column
                break

        return res


class ChildFilter:
    def __init__(self, to_include, node_builder):
        self.node_builder = node_builder
        self.to_include = to_include

    def __call__(self, children):
        filtered = []
        for i, to_expand in self.to_include:
            if to_expand:
                if filtered:
                    filtered += children[i].children
                else:   # Optimize for left-recursion
                    filtered = children[i].children
            else:
                filtered.append(children[i])

        return self.node_builder(filtered)

def _should_expand(sym):
    return not is_terminal(sym) and sym.startswith('_')

def maybe_create_child_filter(expansion, filter_out):
    to_include = [(i, _should_expand(sym)) for i, sym in enumerate(expansion) if sym not in filter_out]

    if len(to_include) < len(expansion) or any(to_expand for i, to_expand in to_include):
        return partial(ChildFilter, to_include)


class Callback(object):
    pass

class ParseTreeBuilder:
    def __init__(self, rules, tree_class, propagate_positions=False, keep_all_tokens=False):
        self.tree_class = tree_class
        self.propagate_positions = propagate_positions
        self.always_keep_all_tokens = keep_all_tokens

        self.rule_builders = list(self._init_builders(rules))

        self.user_aliases = {}

    def _init_builders(self, rules):
        filter_out = {rule.origin for rule in rules if rule.options and rule.options.filter_out}
        filter_out |= {sym for rule in rules for sym in rule.expansion if is_terminal(sym) and sym.startswith('_')}
        assert all(x.startswith('_') for x in filter_out)

        for rule in rules:
            options = rule.options
            keep_all_tokens = self.always_keep_all_tokens or (options.keep_all_tokens if options else False)
            expand_single_child = options.expand1 if options else False
            create_token = options.create_token if options else False

            wrapper_chain = filter(None, [
                create_token and partial(CreateToken, create_token),
                (expand_single_child and not rule.alias) and ExpandSingleChild,
                maybe_create_child_filter(rule.expansion, () if keep_all_tokens else filter_out),
                self.propagate_positions and PropagatePositions,
            ])

            yield rule, wrapper_chain


    def create_callback(self, transformer=None):
        callback = Callback()

        for rule, wrapper_chain in self.rule_builders:
            internal_callback_name = '_callback_%s_%s' % (rule.origin, '_'.join(rule.expansion))

            user_callback_name = rule.alias or rule.origin
            try:
                f = transformer._get_func(user_callback_name)
            except AttributeError:
                f = partial(self.tree_class, user_callback_name)

            self.user_aliases[rule] = rule.alias
            rule.alias = internal_callback_name

            for w in wrapper_chain:
                f = w(f)

            if hasattr(callback, internal_callback_name):
                raise GrammarError("Rule '%s' already exists" % (rule,))
            setattr(callback, internal_callback_name, f)

        return callback



class _Parser:
    def __init__(self, parse_table, callbacks):
        self.states = parse_table.states
        self.start_state = parse_table.start_state
        self.end_state = parse_table.end_state
        self.callbacks = callbacks

    def parse(self, seq, set_state=None):
        i = 0
        token = None
        stream = iter(seq)
        states = self.states

        state_stack = [self.start_state]
        value_stack = []

        if set_state: set_state(self.start_state)

        def get_action(key):
            state = state_stack[-1]
            try:
                return states[state][key]
            except KeyError:
                expected = states[state].keys()

                raise UnexpectedToken(token, expected, seq, i)

        def reduce(rule):
            size = len(rule.expansion)
            if size:
                s = value_stack[-size:]
                del state_stack[-size:]
                del value_stack[-size:]
            else:
                s = []

            value = self.callbacks[rule](s)

            _action, new_state = get_action(rule.origin)
            assert _action is Shift
            state_stack.append(new_state)
            value_stack.append(value)

        # Main LALR-parser loop
        for i, token in enumerate(stream):
            while True:
                action, arg = get_action(token.type)
                assert arg != self.end_state

                if action is Shift:
                    state_stack.append(arg)
                    value_stack.append(token)
                    if set_state: set_state(arg)
                    break # next token
                else:
                    reduce(arg)

        while True:
            _action, arg = get_action('$END')
            if _action is Shift:
                assert arg == self.end_state
                val ,= value_stack
                return val
            else:
                reduce(arg)



class Rule(object):
    """
        origin : a symbol
        expansion : a list of symbols
    """
    def __init__(self, origin, expansion, alias=None, options=None):
        self.origin = origin
        self.expansion = expansion
        self.alias = alias
        self.options = options

    def __str__(self):
        return '<%s : %s>' % (self.origin, ' '.join(map(str,self.expansion)))

    def __repr__(self):
        return 'Rule(%r, %r, %r, %r)' % (self.origin, self.expansion, self.alias, self.options)


class RuleOptions:
    def __init__(self, keep_all_tokens=False, expand1=False, create_token=None, filter_out=False, priority=None):
        self.keep_all_tokens = keep_all_tokens
        self.expand1 = expand1
        self.create_token = create_token  # used for scanless postprocessing
        self.priority = priority

        self.filter_out = filter_out        # remove this rule from the tree
                                            # used for "token"-rules in scanless

    def __repr__(self):
        return 'RuleOptions(%r, %r, %r, %r, %r)' % (
            self.keep_all_tokens,
            self.expand1,
            self.create_token,
            self.priority,
            self.filter_out
        )

Shift = 0
Reduce = 1
import re
MRES = (
[('(?P<SIGNED_FLOAT>(?:(?:\\+|\\-))?(?:(?:[0-9])+(?:e|E)(?:(?:\\+|\\-))?(?:[0-9])+|(?:(?:[0-9])+\\.(?:(?:[0-9])+)?|\\.(?:[0-9])+)(?:(?:e|E)(?:(?:\\+|\\-))?(?:[0-9])+)?))|(?P<SIGNED_INT>(?:(?:\\+|\\-))?(?:[0-9])+)|(?P<ESCAPED_STRING>\\"(?:(?:\\\\\\"|[^"]))*\\")|(?P<WS>(?:(?:\\ '
  '|\t))+)|(?P<__ANONSTR_8>Gphase\\(\\)\\ with\\ t\\=)|(?P<__ANONSTR_5>with\\ '
  'controls\\=\\[)|(?P<NO_CONTROL>with\\ nocontrol)|(?P<__ANONSTR_9>with\\ '
  'anchors\\=\\[)|(?P<__ANONSTR_4>Controllable\\:)|(?P<SUB_CONTROL>(?:(?:yes|no)|classically))|(?P<__ANONSTR_2>Subroutine\\:)|(?P<__SUBROUTINE18>Subroutine)|(?P<__ANONSTR_16>QDiscard\\()|(?P<__ANONSTR_17>CDiscard\\()|(?P<__ANONSTR_1>Outputs\\:)|(?P<__ANONSTR_14>QUnprep\\()|(?P<__ANONSTR_22>Comment\\[)|(?P<__ANONSTR_0>Inputs\\:)|(?P<__ANONSTR_20>\\,\\ '
  'shape)|(?P<CINIT_STATE>(?:CInit0|CInit1))|(?P<CTERM_STATE>(?:CTerm0|CTerm1))|(?P<DTERM_STATE>(?:DTerm0|DTerm1))|(?P<QINIT_STATE>(?:QInit0|QInit1))|(?P<QTERM_STATE>(?:QTerm0|QTerm1))|(?P<__ANONSTR_11>CGate\\[)|(?P<__ANONSTR_12>CSwap\\()|(?P<__ANONSTR_13>QPrep\\()|(?P<__ANONSTR_15>QMeas\\()|(?P<__ANONSTR_21>\\)\\ '
  '\\-\\>\\ '
  '\\()|(?P<__ANONSTR_3>Shape\\:)|(?P<__ANONSTR_6>QGate\\[)|(?P<__ANONSTR_10>CNot\\()|(?P<__ANONSTR_7>QRot\\[)|(?P<TYPE>(?:Qbit|Cbit))|(?P<_NEWLINE>(?:\r'
  ')?\n'
  ')|(?P<__ANONSTR_19>\\(x)|(?P<CR>\r'
  ')|(?P<LF>\n'
  ')|(?P<__COLON>\\:)|(?P<__COMMA>\\,)|(?P<__LPAR>\\()|(?P<__LSQB>\\[)|(?P<__RPAR>\\))|(?P<__RSQB>\\])|(?P<__STAR>\\*)',
  {1: 'SIGNED_FLOAT',
   2: 'SIGNED_INT',
   3: 'ESCAPED_STRING',
   4: 'WS',
   5: '__ANONSTR_8',
   6: '__ANONSTR_5',
   7: 'NO_CONTROL',
   8: '__ANONSTR_9',
   9: '__ANONSTR_4',
   10: 'SUB_CONTROL',
   11: '__ANONSTR_2',
   12: '__SUBROUTINE18',
   13: '__ANONSTR_16',
   14: '__ANONSTR_17',
   15: '__ANONSTR_1',
   16: '__ANONSTR_14',
   17: '__ANONSTR_22',
   18: '__ANONSTR_0',
   19: '__ANONSTR_20',
   20: 'CINIT_STATE',
   21: 'CTERM_STATE',
   22: 'DTERM_STATE',
   23: 'QINIT_STATE',
   24: 'QTERM_STATE',
   25: '__ANONSTR_11',
   26: '__ANONSTR_12',
   27: '__ANONSTR_13',
   28: '__ANONSTR_15',
   29: '__ANONSTR_21',
   30: '__ANONSTR_3',
   31: '__ANONSTR_6',
   32: '__ANONSTR_10',
   33: '__ANONSTR_7',
   34: 'TYPE',
   35: '_NEWLINE',
   36: '__ANONSTR_19',
   37: 'CR',
   38: 'LF',
   39: '__COLON',
   40: '__COMMA',
   41: '__LPAR',
   42: '__LSQB',
   43: '__RPAR',
   44: '__RSQB',
   45: '__STAR'})]
)
LEXER_CALLBACK = (
{}
)
NEWLINE_TYPES = ['_NEWLINE', 'LF']
IGNORE_TYPES = ['WS']
class LexerRegexps: pass
lexer_regexps = LexerRegexps()
lexer_regexps.mres = [(re.compile(p), d) for p, d in MRES]
lexer_regexps.callback = {n: UnlessCallback([(re.compile(p), d) for p, d in mres])
                          for n, mres in LEXER_CALLBACK.items()}
lexer = _Lex(lexer_regexps)
def lex(stream):
    return lexer.lex(stream, NEWLINE_TYPES, IGNORE_TYPES)
RULES = {
  0: Rule('start', ['circuit', '__anon_star_0', '__anon_star_1'], None, RuleOptions(False, False, None, None, False)),
  1: Rule('start', ['circuit', '__anon_star_1'], None, RuleOptions(False, False, None, None, False)),
  2: Rule('start', ['circuit'], None, RuleOptions(False, False, None, None, False)),
  3: Rule('start', ['circuit', '__anon_star_0'], None, RuleOptions(False, False, None, None, False)),
  4: Rule('circuit', ['__ANONSTR_0', 'arity', '__ANONSTR_1', 'arity'], None, RuleOptions(False, False, None, None, False)),
  5: Rule('circuit', ['__ANONSTR_0', 'arity', '__anon_star_2', '__ANONSTR_1', 'arity'], None, RuleOptions(False, False, None, None, False)),
  6: Rule('subroutine', ['_NEWLINE', '__ANONSTR_2', 'string', '_NEWLINE', '__ANONSTR_3', 'string', '_NEWLINE', '__ANONSTR_4', 'SUB_CONTROL', '_NEWLINE', 'circuit'], None, RuleOptions(False, False, None, None, False)),
  7: Rule('arity', ['type_assignment', '__anon_star_3', '__COMMA', '_NEWLINE'], None, RuleOptions(False, False, None, None, False)),
  8: Rule('arity', ['type_assignment', '_NEWLINE'], None, RuleOptions(False, False, None, None, False)),
  9: Rule('arity', ['type_assignment', '__COMMA', '_NEWLINE'], None, RuleOptions(False, False, None, None, False)),
  10: Rule('arity', ['type_assignment', '__anon_star_3', '_NEWLINE'], None, RuleOptions(False, False, None, None, False)),
  11: Rule('type_assignment', ['wire', '__COLON', 'TYPE'], None, RuleOptions(False, False, None, None, False)),
  12: Rule('control_app', ['controlled'], None, RuleOptions(False, False, None, None, False)),
  13: Rule('control_app', ['NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  14: Rule('control_app', ['controlled', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  15: Rule('control_app', [], None, RuleOptions(False, False, None, None, False)),
  16: Rule('controlled', ['__ANONSTR_5', 'wire_list', '__RSQB'], None, RuleOptions(False, True, None, None, False)),
  17: Rule('gate', ['gphase'], None, RuleOptions(False, True, None, None, False)),
  18: Rule('gate', ['qunprep'], None, RuleOptions(False, True, None, None, False)),
  19: Rule('gate', ['subroutine_call'], None, RuleOptions(False, True, None, None, False)),
  20: Rule('gate', ['qrot'], None, RuleOptions(False, True, None, None, False)),
  21: Rule('gate', ['qinit'], None, RuleOptions(False, True, None, None, False)),
  22: Rule('gate', ['qmeas'], None, RuleOptions(False, True, None, None, False)),
  23: Rule('gate', ['cgate'], None, RuleOptions(False, True, None, None, False)),
  24: Rule('gate', ['dterm'], None, RuleOptions(False, True, None, None, False)),
  25: Rule('gate', ['qgate'], None, RuleOptions(False, True, None, None, False)),
  26: Rule('gate', ['qprep'], None, RuleOptions(False, True, None, None, False)),
  27: Rule('gate', ['qdiscard'], None, RuleOptions(False, True, None, None, False)),
  28: Rule('gate', ['cnot'], None, RuleOptions(False, True, None, None, False)),
  29: Rule('gate', ['qterm'], None, RuleOptions(False, True, None, None, False)),
  30: Rule('gate', ['cswap'], None, RuleOptions(False, True, None, None, False)),
  31: Rule('gate', ['cterm'], None, RuleOptions(False, True, None, None, False)),
  32: Rule('gate', ['cdiscard'], None, RuleOptions(False, True, None, None, False)),
  33: Rule('gate', ['cinit'], None, RuleOptions(False, True, None, None, False)),
  34: Rule('gate', ['comment'], None, RuleOptions(False, True, None, None, False)),
  35: Rule('inversion', [], None, RuleOptions(True, False, None, None, False)),
  36: Rule('inversion', ['__STAR'], None, RuleOptions(True, False, None, None, False)),
  37: Rule('qgate', ['__ANONSTR_6', 'string', '__RSQB', 'inversion', '__LPAR', 'wire', '__RPAR', 'control_app'], None, RuleOptions(False, False, None, None, False)),
  38: Rule('qrot', ['__ANONSTR_7', 'string', '__COMMA', 'float', '__RSQB', 'inversion', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  39: Rule('gphase', ['__ANONSTR_8', 'float', 'control_app', '__ANONSTR_9', 'wire_list', '__RSQB'], None, RuleOptions(False, False, None, None, False)),
  40: Rule('cnot', ['__ANONSTR_10', 'wire', '__RPAR', 'control_app'], None, RuleOptions(False, False, None, None, False)),
  41: Rule('cgate', ['__ANONSTR_11', 'string', '__RSQB', 'inversion', '__LPAR', 'wire_list', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  42: Rule('cgate', ['__ANONSTR_11', 'string', '__RSQB', 'inversion', '__LPAR', 'wire_list', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  43: Rule('cswap', ['__ANONSTR_12', 'wire', '__COMMA', 'wire', '__RPAR', 'control_app'], None, RuleOptions(False, False, None, None, False)),
  44: Rule('qprep', ['__ANONSTR_13', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  45: Rule('qprep', ['__ANONSTR_13', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  46: Rule('qunprep', ['__ANONSTR_14', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  47: Rule('qunprep', ['__ANONSTR_14', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  48: Rule('qinit', ['QINIT_STATE', '__LPAR', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  49: Rule('qinit', ['QINIT_STATE', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  50: Rule('cinit', ['CINIT_STATE', '__LPAR', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  51: Rule('cinit', ['CINIT_STATE', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  52: Rule('qterm', ['QTERM_STATE', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  53: Rule('qterm', ['QTERM_STATE', '__LPAR', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  54: Rule('cterm', ['CTERM_STATE', '__LPAR', 'wire', '__RPAR', 'NO_CONTROL'], None, RuleOptions(False, False, None, None, False)),
  55: Rule('cterm', ['CTERM_STATE', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  56: Rule('qmeas', ['__ANONSTR_15', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  57: Rule('qdiscard', ['__ANONSTR_16', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  58: Rule('cdiscard', ['__ANONSTR_17', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  59: Rule('dterm', ['DTERM_STATE', '__LPAR', 'wire', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  60: Rule('subroutine_call', ['__SUBROUTINE18', '__LSQB', 'string', '__ANONSTR_20', 'string', '__RSQB', 'inversion', '__LPAR', 'wire_list', '__ANONSTR_21', 'wire_list', '__RPAR', 'control_app'], None, RuleOptions(False, False, None, None, False)),
  61: Rule('subroutine_call', ['__SUBROUTINE18', '__ANONSTR_19', 'int', '__RPAR', '__LSQB', 'string', '__ANONSTR_20', 'string', '__RSQB', 'inversion', '__LPAR', 'wire_list', '__ANONSTR_21', 'wire_list', '__RPAR', 'control_app'], None, RuleOptions(False, False, None, None, False)),
  62: Rule('comment', ['__ANONSTR_22', 'string', '__RSQB', 'inversion', '__LPAR', 'wire_string_list', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  63: Rule('comment', ['__ANONSTR_22', 'string', '__RSQB', 'inversion', '__LPAR', '__RPAR'], None, RuleOptions(False, False, None, None, False)),
  64: Rule('wire_string_list', ['wire', '__COLON', 'string', '__anon_star_4'], None, RuleOptions(False, False, None, None, False)),
  65: Rule('wire_string_list', ['wire', '__COLON', 'string'], None, RuleOptions(False, False, None, None, False)),
  66: Rule('wire', ['int'], None, RuleOptions(False, False, None, None, False)),
  67: Rule('wire_list', ['wire', '__anon_star_5'], None, RuleOptions(False, False, None, None, False)),
  68: Rule('wire_list', ['wire'], None, RuleOptions(False, False, None, None, False)),
  69: Rule('string', ['ESCAPED_STRING'], None, RuleOptions(False, False, None, None, False)),
  70: Rule('float', ['SIGNED_FLOAT'], None, RuleOptions(False, False, None, None, False)),
  71: Rule('int', ['SIGNED_INT'], None, RuleOptions(False, False, None, None, False)),
  72: Rule('__anon_star_0', ['__anon_star_0', 'subroutine'], None, None),
  73: Rule('__anon_star_0', ['subroutine'], None, None),
  74: Rule('__anon_star_1', ['__anon_star_1', '_NEWLINE'], None, None),
  75: Rule('__anon_star_1', ['_NEWLINE'], None, None),
  76: Rule('__anon_star_2', ['__anon_star_2', 'gate', '_NEWLINE'], None, None),
  77: Rule('__anon_star_2', ['gate', '_NEWLINE'], None, None),
  78: Rule('__anon_star_3', ['__anon_star_3', '__COMMA', 'type_assignment'], None, None),
  79: Rule('__anon_star_3', ['__COMMA', 'type_assignment'], None, None),
  80: Rule('__anon_star_4', ['__COMMA', 'wire', '__COLON', 'string'], None, None),
  81: Rule('__anon_star_4', ['__anon_star_4', '__COMMA', 'wire', '__COLON', 'string'], None, None),
  82: Rule('__anon_star_5', ['__COMMA', 'wire'], None, None),
  83: Rule('__anon_star_5', ['__anon_star_5', '__COMMA', 'wire'], None, None),
}
parse_tree_builder = ParseTreeBuilder(RULES.values(), Tree)
class ParseTable: pass
parse_table = ParseTable()
STATES = {
  0: {0: (0, 1), 1: (0, 2), 2: (0, 3)},
  1: {3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8)},
  2: {8: (0, 9)},
  3: {8: (1, 2), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13)},
  4: {13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52)},
  5: {52: (1, 71), 53: (1, 71), 54: (1, 71), 55: (1, 71), 56: (1, 71)},
  6: {10: (0, 53), 53: (0, 54), 57: (0, 55)},
  7: {52: (0, 56)},
  8: {53: (1, 66), 54: (1, 66), 52: (1, 66), 55: (1, 66), 56: (1, 66)},
  9: {},
  10: {8: (1, 1), 10: (0, 57)},
  11: {8: (1, 75), 10: (1, 75), 58: (0, 58)},
  12: {8: (1, 3), 9: (0, 59), 12: (0, 60), 10: (0, 11)},
  13: {8: (1, 73), 10: (1, 73)},
  14: {59: (0, 61)},
  15: {60: (0, 62), 61: (0, 63)},
  16: {3: (0, 64), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8)},
  17: {6: (0, 65), 7: (0, 8), 4: (0, 5)},
  18: {59: (0, 66)},
  19: {61: (0, 63), 60: (0, 67)},
  20: {59: (0, 68)},
  21: {59: (0, 69)},
  22: {62: (0, 70), 63: (0, 71)},
  23: {10: (1, 24)},
  24: {10: (1, 27)},
  25: {61: (0, 63), 60: (0, 72)},
  26: {10: (1, 28)},
  27: {7: (0, 8), 6: (0, 73), 4: (0, 5)},
  28: {10: (1, 22)},
  29: {10: (1, 26)},
  30: {64: (0, 74), 65: (0, 75)},
  31: {7: (0, 8), 4: (0, 5), 6: (0, 76)},
  32: {59: (0, 77)},
  33: {10: (1, 34)},
  34: {61: (0, 63), 60: (0, 78)},
  35: {7: (0, 8), 4: (0, 5), 6: (0, 79)},
  36: {10: (1, 21)},
  37: {7: (0, 8), 6: (0, 80), 4: (0, 5)},
  38: {10: (1, 31)},
  39: {10: (0, 81)},
  40: {13: (0, 14), 14: (0, 15), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 38: (0, 82), 15: (0, 83), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52)},
  41: {10: (1, 17)},
  42: {10: (1, 25)},
  43: {10: (1, 30)},
  44: {6: (0, 84), 7: (0, 8), 4: (0, 5)},
  45: {10: (1, 29)},
  46: {10: (1, 19)},
  47: {10: (1, 20)},
  48: {10: (1, 33)},
  49: {6: (0, 85), 7: (0, 8), 4: (0, 5)},
  50: {10: (1, 18)},
  51: {10: (1, 23)},
  52: {10: (1, 32)},
  53: {30: (1, 8), 21: (1, 8), 10: (1, 8), 16: (1, 8), 31: (1, 8), 34: (1, 8), 17: (1, 8), 13: (1, 8), 18: (1, 8), 29: (1, 8), 33: (1, 8), 14: (1, 8), 36: (1, 8), 19: (1, 8), 48: (1, 8), 8: (1, 8), 20: (1, 8), 15: (1, 8), 26: (1, 8), 43: (1, 8), 24: (1, 8)},
  54: {10: (0, 86), 4: (0, 5), 5: (0, 87), 6: (0, 7), 7: (0, 8)},
  55: {53: (0, 88), 10: (0, 89)},
  56: {66: (0, 90)},
  57: {8: (1, 74), 10: (1, 74)},
  58: {61: (0, 63), 60: (0, 91)},
  59: {8: (1, 0), 10: (0, 57)},
  60: {8: (1, 72), 10: (1, 72)},
  61: {7: (0, 8), 4: (0, 5), 6: (0, 92)},
  62: {55: (0, 93)},
  63: {55: (1, 69), 53: (1, 69), 54: (1, 69), 10: (1, 69), 67: (1, 69)},
  64: {8: (1, 4), 10: (1, 4)},
  65: {54: (0, 94)},
  66: {7: (0, 8), 4: (0, 5), 6: (0, 95)},
  67: {53: (0, 96)},
  68: {6: (0, 97), 7: (0, 8), 4: (0, 5)},
  69: {6: (0, 98), 7: (0, 8), 4: (0, 5)},
  70: {68: (1, 70), 69: (1, 70), 55: (1, 70), 70: (1, 70)},
  71: {69: (1, 15), 10: (1, 15), 71: (0, 99), 68: (0, 100), 72: (0, 101), 70: (0, 102)},
  72: {55: (0, 103)},
  73: {54: (0, 104)},
  74: {7: (0, 105), 4: (0, 5)},
  75: {61: (0, 63), 60: (0, 106)},
  76: {54: (0, 107)},
  77: {6: (0, 108), 7: (0, 8), 4: (0, 5)},
  78: {55: (0, 109)},
  79: {53: (0, 110)},
  80: {54: (0, 111)},
  81: {30: (1, 77), 21: (1, 77), 16: (1, 77), 31: (1, 77), 34: (1, 77), 17: (1, 77), 13: (1, 77), 18: (1, 77), 29: (1, 77), 33: (1, 77), 14: (1, 77), 36: (1, 77), 19: (1, 77), 48: (1, 77), 20: (1, 77), 15: (1, 77), 26: (1, 77), 43: (1, 77), 24: (1, 77)},
  82: {10: (0, 112)},
  83: {4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 3: (0, 113)},
  84: {54: (0, 114)},
  85: {54: (0, 115)},
  86: {30: (1, 9), 21: (1, 9), 10: (1, 9), 16: (1, 9), 31: (1, 9), 34: (1, 9), 17: (1, 9), 13: (1, 9), 18: (1, 9), 29: (1, 9), 33: (1, 9), 14: (1, 9), 36: (1, 9), 19: (1, 9), 48: (1, 9), 8: (1, 9), 20: (1, 9), 15: (1, 9), 26: (1, 9), 43: (1, 9), 24: (1, 9)},
  87: {53: (1, 79), 10: (1, 79)},
  88: {5: (0, 116), 4: (0, 5), 6: (0, 7), 7: (0, 8), 10: (0, 117)},
  89: {30: (1, 10), 21: (1, 10), 10: (1, 10), 16: (1, 10), 31: (1, 10), 34: (1, 10), 17: (1, 10), 13: (1, 10), 18: (1, 10), 29: (1, 10), 33: (1, 10), 14: (1, 10), 36: (1, 10), 19: (1, 10), 48: (1, 10), 8: (1, 10), 20: (1, 10), 15: (1, 10), 26: (1, 10), 43: (1, 10), 24: (1, 10)},
  90: {53: (1, 11), 10: (1, 11)},
  91: {10: (0, 118)},
  92: {54: (0, 119)},
  93: {59: (1, 35), 73: (0, 120), 74: (0, 121)},
  94: {10: (1, 44), 68: (0, 122)},
  95: {54: (0, 123)},
  96: {63: (0, 124), 62: (0, 70)},
  97: {54: (0, 125)},
  98: {54: (0, 126)},
  99: {69: (1, 12), 10: (1, 12), 68: (0, 127)},
  100: {69: (1, 13), 10: (1, 13)},
  101: {69: (0, 128)},
  102: {75: (0, 129), 4: (0, 5), 6: (0, 130), 7: (0, 8)},
  103: {59: (1, 35), 73: (0, 131), 74: (0, 121)},
  104: {10: (1, 47), 68: (0, 132)},
  105: {54: (0, 133)},
  106: {67: (0, 134)},
  107: {10: (1, 58)},
  108: {54: (0, 135)},
  109: {59: (1, 35), 73: (0, 136), 74: (0, 121)},
  110: {7: (0, 8), 6: (0, 137), 4: (0, 5)},
  111: {10: (1, 56)},
  112: {30: (1, 76), 21: (1, 76), 16: (1, 76), 31: (1, 76), 34: (1, 76), 17: (1, 76), 13: (1, 76), 18: (1, 76), 29: (1, 76), 33: (1, 76), 14: (1, 76), 36: (1, 76), 19: (1, 76), 48: (1, 76), 20: (1, 76), 15: (1, 76), 26: (1, 76), 43: (1, 76), 24: (1, 76)},
  113: {8: (1, 5), 10: (1, 5)},
  114: {10: (1, 57)},
  115: {69: (1, 15), 10: (1, 15), 71: (0, 99), 72: (0, 138), 68: (0, 100), 70: (0, 102)},
  116: {53: (1, 78), 10: (1, 78)},
  117: {30: (1, 7), 21: (1, 7), 10: (1, 7), 16: (1, 7), 31: (1, 7), 34: (1, 7), 17: (1, 7), 13: (1, 7), 18: (1, 7), 29: (1, 7), 33: (1, 7), 14: (1, 7), 36: (1, 7), 19: (1, 7), 48: (1, 7), 8: (1, 7), 20: (1, 7), 15: (1, 7), 26: (1, 7), 43: (1, 7), 24: (1, 7)},
  118: {76: (0, 139)},
  119: {10: (1, 59)},
  120: {59: (0, 140)},
  121: {59: (1, 36)},
  122: {10: (1, 45)},
  123: {10: (1, 49), 68: (0, 141)},
  124: {55: (0, 142)},
  125: {10: (1, 55), 68: (0, 143)},
  126: {10: (1, 52), 68: (0, 144)},
  127: {69: (1, 14), 10: (1, 14)},
  128: {4: (0, 5), 75: (0, 145), 6: (0, 130), 7: (0, 8)},
  129: {55: (0, 146)},
  130: {55: (1, 68), 56: (1, 68), 54: (1, 68), 53: (0, 147), 77: (0, 148)},
  131: {59: (0, 149)},
  132: {10: (1, 46)},
  133: {65: (0, 150)},
  134: {61: (0, 63), 60: (0, 151)},
  135: {10: (1, 51), 68: (0, 152)},
  136: {59: (0, 153)},
  137: {54: (0, 154)},
  138: {10: (1, 40)},
  139: {61: (0, 63), 60: (0, 155)},
  140: {54: (0, 156), 78: (0, 157), 4: (0, 5), 6: (0, 158), 7: (0, 8)},
  141: {10: (1, 48)},
  142: {59: (1, 35), 73: (0, 159), 74: (0, 121)},
  143: {10: (1, 54)},
  144: {10: (1, 53)},
  145: {55: (0, 160)},
  146: {68: (1, 16), 10: (1, 16), 69: (1, 16)},
  147: {7: (0, 8), 4: (0, 5), 6: (0, 161)},
  148: {55: (1, 67), 56: (1, 67), 54: (1, 67), 53: (0, 162)},
  149: {75: (0, 163), 4: (0, 5), 6: (0, 130), 7: (0, 8)},
  150: {61: (0, 63), 60: (0, 164)},
  151: {55: (0, 165)},
  152: {10: (1, 50)},
  153: {6: (0, 166), 7: (0, 8), 4: (0, 5)},
  154: {69: (1, 15), 10: (1, 15), 71: (0, 99), 68: (0, 100), 72: (0, 167), 70: (0, 102)},
  155: {10: (0, 168)},
  156: {10: (1, 63)},
  157: {54: (0, 169)},
  158: {52: (0, 170)},
  159: {59: (0, 171)},
  160: {10: (1, 39)},
  161: {53: (1, 82), 54: (1, 82), 55: (1, 82), 56: (1, 82)},
  162: {7: (0, 8), 6: (0, 172), 4: (0, 5)},
  163: {54: (0, 173)},
  164: {67: (0, 174)},
  165: {59: (1, 35), 73: (0, 175), 74: (0, 121)},
  166: {54: (0, 176)},
  167: {10: (1, 43)},
  168: {79: (0, 177)},
  169: {10: (1, 62)},
  170: {60: (0, 178), 61: (0, 63)},
  171: {7: (0, 8), 4: (0, 5), 6: (0, 179)},
  172: {53: (1, 83), 54: (1, 83), 55: (1, 83), 56: (1, 83)},
  173: {10: (1, 41), 68: (0, 180)},
  174: {61: (0, 63), 60: (0, 181)},
  175: {59: (0, 182)},
  176: {69: (1, 15), 10: (1, 15), 71: (0, 99), 68: (0, 100), 70: (0, 102), 72: (0, 183)},
  177: {80: (0, 184)},
  178: {54: (1, 65), 81: (0, 185), 53: (0, 186)},
  179: {54: (0, 187)},
  180: {10: (1, 42)},
  181: {55: (0, 188)},
  182: {4: (0, 5), 7: (0, 8), 75: (0, 189), 6: (0, 130)},
  183: {10: (1, 37)},
  184: {10: (0, 190)},
  185: {54: (1, 64), 53: (0, 191)},
  186: {7: (0, 8), 6: (0, 192), 4: (0, 5)},
  187: {10: (1, 38)},
  188: {59: (1, 35), 73: (0, 193), 74: (0, 121)},
  189: {56: (0, 194)},
  190: {0: (0, 1), 2: (0, 195)},
  191: {7: (0, 8), 4: (0, 5), 6: (0, 196)},
  192: {52: (0, 197)},
  193: {59: (0, 198)},
  194: {4: (0, 5), 6: (0, 130), 7: (0, 8), 75: (0, 199)},
  195: {8: (1, 6), 10: (1, 6)},
  196: {52: (0, 200)},
  197: {60: (0, 201), 61: (0, 63)},
  198: {4: (0, 5), 6: (0, 130), 7: (0, 8), 75: (0, 202)},
  199: {54: (0, 203)},
  200: {61: (0, 63), 60: (0, 204)},
  201: {53: (1, 80), 54: (1, 80)},
  202: {56: (0, 205)},
  203: {69: (1, 15), 10: (1, 15), 71: (0, 99), 72: (0, 206), 68: (0, 100), 70: (0, 102)},
  204: {53: (1, 81), 54: (1, 81)},
  205: {4: (0, 5), 7: (0, 8), 75: (0, 207), 6: (0, 130)},
  206: {10: (1, 60)},
  207: {54: (0, 208)},
  208: {69: (1, 15), 10: (1, 15), 71: (0, 99), 68: (0, 100), 70: (0, 102), 72: (0, 209)},
  209: {10: (1, 61)},
}
TOKEN_TYPES = (
{0: '__ANONSTR_0',
 1: 'start',
 2: 'circuit',
 3: 'arity',
 4: 'SIGNED_INT',
 5: 'type_assignment',
 6: 'wire',
 7: 'int',
 8: '$END',
 9: '__anon_star_1',
 10: '_NEWLINE',
 11: '__anon_star_0',
 12: 'subroutine',
 13: 'DTERM_STATE',
 14: '__ANONSTR_22',
 15: '__ANONSTR_1',
 16: '__ANONSTR_13',
 17: 'QINIT_STATE',
 18: '__ANONSTR_7',
 19: 'CTERM_STATE',
 20: 'QTERM_STATE',
 21: '__ANONSTR_8',
 22: 'dterm',
 23: 'qdiscard',
 24: '__ANONSTR_11',
 25: 'cnot',
 26: '__ANONSTR_14',
 27: 'qmeas',
 28: 'qprep',
 29: '__SUBROUTINE18',
 30: '__ANONSTR_17',
 31: 'CINIT_STATE',
 32: 'comment',
 33: '__ANONSTR_6',
 34: '__ANONSTR_12',
 35: 'qinit',
 36: '__ANONSTR_15',
 37: 'cterm',
 38: 'gate',
 39: '__anon_star_2',
 40: 'gphase',
 41: 'qgate',
 42: 'cswap',
 43: '__ANONSTR_16',
 44: 'qterm',
 45: 'subroutine_call',
 46: 'qrot',
 47: 'cinit',
 48: '__ANONSTR_10',
 49: 'qunprep',
 50: 'cgate',
 51: 'cdiscard',
 52: '__COLON',
 53: '__COMMA',
 54: '__RPAR',
 55: '__RSQB',
 56: '__ANONSTR_21',
 57: '__anon_star_3',
 58: '__ANONSTR_2',
 59: '__LPAR',
 60: 'string',
 61: 'ESCAPED_STRING',
 62: 'SIGNED_FLOAT',
 63: 'float',
 64: '__ANONSTR_19',
 65: '__LSQB',
 66: 'TYPE',
 67: '__ANONSTR_20',
 68: 'NO_CONTROL',
 69: '__ANONSTR_9',
 70: '__ANONSTR_5',
 71: 'controlled',
 72: 'control_app',
 73: 'inversion',
 74: '__STAR',
 75: 'wire_list',
 76: '__ANONSTR_3',
 77: '__anon_star_5',
 78: 'wire_string_list',
 79: '__ANONSTR_4',
 80: 'SUB_CONTROL',
 81: '__anon_star_4'}
)
parse_table.states = {s: {TOKEN_TYPES[t]: (a, RULES[x] if a is Reduce else x) for t, (a, x) in acts.items()}
                      for s, acts in STATES.items()}
parse_table.start_state = 0
parse_table.end_state = 9
class Lark_StandAlone:
  def __init__(self, transformer=None, postlex=None):
     callback = parse_tree_builder.create_callback(transformer=transformer)
     callbacks = {rule: getattr(callback, rule.alias or rule.origin, None) for rule in RULES.values()}
     self.parser = _Parser(parse_table, callbacks)
     self.postlex = postlex
  def parse(self, stream):
     tokens = lex(stream)
     if self.postlex: tokens = self.postlex.process(tokens)
     return self.parser.parse(tokens)
